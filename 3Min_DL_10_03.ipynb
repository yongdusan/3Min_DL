{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "seq_data = [['word', '단어'], ['wood', '나무'],\n",
    "            ['game', '놀이'], ['girl', '소녀'],\n",
    "            ['kiss', '키스'], ['love', '사랑']]\n",
    "\n",
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "        \n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "    \n",
    "    return input_batch, output_batch, target_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 100\n",
    "\n",
    "n_class = n_input = dic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "dec_input = tf.placeholder(tf.float32, [None, None, n_input])\n",
    "targets = tf.placeholder(tf.int64, [None, None])\n",
    "\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell,\n",
    "                                             output_keep_prob = 0.5)\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input,\n",
    "                                            dtype = tf.float32)\n",
    "\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob = 0.5)\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input, \n",
    "                                            initial_state = enc_states, dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels = targets))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost =  3.709091\n",
      "Epoch:  0002 cost =  2.589462\n",
      "Epoch:  0003 cost =  1.645779\n",
      "Epoch:  0004 cost =  0.905564\n",
      "Epoch:  0005 cost =  0.625466\n",
      "Epoch:  0006 cost =  0.374862\n",
      "Epoch:  0007 cost =  0.415978\n",
      "Epoch:  0008 cost =  0.159362\n",
      "Epoch:  0009 cost =  0.215484\n",
      "Epoch:  0010 cost =  0.140496\n",
      "Epoch:  0011 cost =  0.180748\n",
      "Epoch:  0012 cost =  0.129443\n",
      "Epoch:  0013 cost =  0.189756\n",
      "Epoch:  0014 cost =  0.202588\n",
      "Epoch:  0015 cost =  0.109811\n",
      "Epoch:  0016 cost =  0.060038\n",
      "Epoch:  0017 cost =  0.087649\n",
      "Epoch:  0018 cost =  0.041391\n",
      "Epoch:  0019 cost =  0.043085\n",
      "Epoch:  0020 cost =  0.051606\n",
      "Epoch:  0021 cost =  0.060835\n",
      "Epoch:  0022 cost =  0.013817\n",
      "Epoch:  0023 cost =  0.074167\n",
      "Epoch:  0024 cost =  0.021245\n",
      "Epoch:  0025 cost =  0.088102\n",
      "Epoch:  0026 cost =  0.011744\n",
      "Epoch:  0027 cost =  0.008758\n",
      "Epoch:  0028 cost =  0.045453\n",
      "Epoch:  0029 cost =  0.025833\n",
      "Epoch:  0030 cost =  0.002582\n",
      "Epoch:  0031 cost =  0.006670\n",
      "Epoch:  0032 cost =  0.005177\n",
      "Epoch:  0033 cost =  0.005703\n",
      "Epoch:  0034 cost =  0.001835\n",
      "Epoch:  0035 cost =  0.003802\n",
      "Epoch:  0036 cost =  0.013738\n",
      "Epoch:  0037 cost =  0.003239\n",
      "Epoch:  0038 cost =  0.019278\n",
      "Epoch:  0039 cost =  0.001376\n",
      "Epoch:  0040 cost =  0.002508\n",
      "Epoch:  0041 cost =  0.000930\n",
      "Epoch:  0042 cost =  0.001737\n",
      "Epoch:  0043 cost =  0.000702\n",
      "Epoch:  0044 cost =  0.001926\n",
      "Epoch:  0045 cost =  0.002456\n",
      "Epoch:  0046 cost =  0.000624\n",
      "Epoch:  0047 cost =  0.001201\n",
      "Epoch:  0048 cost =  0.002704\n",
      "Epoch:  0049 cost =  0.000432\n",
      "Epoch:  0050 cost =  0.001277\n",
      "Epoch:  0051 cost =  0.001519\n",
      "Epoch:  0052 cost =  0.001060\n",
      "Epoch:  0053 cost =  0.000661\n",
      "Epoch:  0054 cost =  0.001128\n",
      "Epoch:  0055 cost =  0.000840\n",
      "Epoch:  0056 cost =  0.000668\n",
      "Epoch:  0057 cost =  0.000613\n",
      "Epoch:  0058 cost =  0.000464\n",
      "Epoch:  0059 cost =  0.000565\n",
      "Epoch:  0060 cost =  0.000904\n",
      "Epoch:  0061 cost =  0.000344\n",
      "Epoch:  0062 cost =  0.000216\n",
      "Epoch:  0063 cost =  0.000746\n",
      "Epoch:  0064 cost =  0.000274\n",
      "Epoch:  0065 cost =  0.000714\n",
      "Epoch:  0066 cost =  0.001269\n",
      "Epoch:  0067 cost =  0.000330\n",
      "Epoch:  0068 cost =  0.000788\n",
      "Epoch:  0069 cost =  0.005082\n",
      "Epoch:  0070 cost =  0.000573\n",
      "Epoch:  0071 cost =  0.000485\n",
      "Epoch:  0072 cost =  0.001492\n",
      "Epoch:  0073 cost =  0.001818\n",
      "Epoch:  0074 cost =  0.000275\n",
      "Epoch:  0075 cost =  0.000515\n",
      "Epoch:  0076 cost =  0.000771\n",
      "Epoch:  0077 cost =  0.000438\n",
      "Epoch:  0078 cost =  0.000376\n",
      "Epoch:  0079 cost =  0.000149\n",
      "Epoch:  0080 cost =  0.000818\n",
      "Epoch:  0081 cost =  0.001156\n",
      "Epoch:  0082 cost =  0.001383\n",
      "Epoch:  0083 cost =  0.000666\n",
      "Epoch:  0084 cost =  0.000800\n",
      "Epoch:  0085 cost =  0.000313\n",
      "Epoch:  0086 cost =  0.000234\n",
      "Epoch:  0087 cost =  0.000501\n",
      "Epoch:  0088 cost =  0.000387\n",
      "Epoch:  0089 cost =  0.000336\n",
      "Epoch:  0090 cost =  0.000286\n",
      "Epoch:  0091 cost =  0.000435\n",
      "Epoch:  0092 cost =  0.000436\n",
      "Epoch:  0093 cost =  0.000411\n",
      "Epoch:  0094 cost =  0.000371\n",
      "Epoch:  0095 cost =  0.000319\n",
      "Epoch:  0096 cost =  0.000480\n",
      "Epoch:  0097 cost =  0.001099\n",
      "Epoch:  0098 cost =  0.001227\n",
      "Epoch:  0099 cost =  0.000281\n",
      "Epoch:  0100 cost =  0.001055\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "input_batch, output_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],\n",
    "                       feed_dict={enc_input: input_batch,\n",
    "                                  dec_input: output_batch,\n",
    "                                  targets: target_batch})\n",
    "    print('Epoch: ', '%04d' % (epoch + 1),\n",
    "          'cost = ', '{:.6f}'.format(loss))\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    seq_data = [word, 'P' * len(word)]\n",
    "    \n",
    "    input_batch, output_batch, target_batch = make_batch([seq_data])\n",
    "    \n",
    "    prediction = tf.argmax(model, 2)\n",
    "    \n",
    "    result = sess.run(prediction, feed_dict = {enc_input: input_batch, dec_input: output_batch, targets: target_batch})\n",
    "    \n",
    "    decoded = [char_arr[i] for i in result[0]]\n",
    "    \n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "    \n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === 번역 테스트 ===\n",
      "word -> 단어\n",
      "wodr -> 단무\n",
      "love -> 사랑\n",
      "loev -> 사랑\n",
      "abcd -> 사랑\n",
      "kiss -> 키스\n"
     ]
    }
   ],
   "source": [
    "print('\\n === 번역 테스트 ===')\n",
    "\n",
    "print('word ->', translate('word'))\n",
    "print('wodr ->', translate('wodr'))\n",
    "print('love ->', translate('love'))\n",
    "print('loev ->', translate('loev'))\n",
    "print('abcd ->', translate('abcd'))\n",
    "print('kiss ->', translate('kiss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
